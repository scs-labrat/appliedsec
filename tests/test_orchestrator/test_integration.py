"""Integration tests — Story 7.10.

End-to-end validation with mocked backends.
"""

import json

import pytest
from unittest.mock import AsyncMock, MagicMock

from shared.schemas.investigation import GraphState, InvestigationState
from orchestrator.persistence import InvestigationRepository
from orchestrator.graph import InvestigationGraph
from orchestrator.fp_shortcircuit import FPShortCircuit
from orchestrator.agents.ioc_extractor import IOCExtractorAgent
from orchestrator.agents.context_enricher import ContextEnricherAgent
from orchestrator.agents.reasoning_agent import ReasoningAgent
from orchestrator.agents.response_agent import ResponseAgent
from orchestrator.agents.ctem_correlator import CTEMCorrelatorAgent
from orchestrator.agents.atlas_mapper import ATLASMapperAgent


def _make_mock_gateway(classification: dict):
    gw = AsyncMock()
    gw.complete = AsyncMock(return_value=MagicMock(
        content=json.dumps(classification),
        metrics=MagicMock(cost_usd=0.01),
    ))
    return gw


def _make_mock_redis():
    redis = AsyncMock()
    redis.get_ioc = AsyncMock(return_value={
        "confidence": 0.85,
        "severity": "high",
        "campaigns": ["Test Campaign"],
    })
    redis.list_fp_patterns = AsyncMock(return_value=[])
    redis.get_fp_pattern = AsyncMock(return_value=None)
    return redis


def _make_mock_postgres():
    pg = AsyncMock()
    pg.execute = AsyncMock()
    pg.fetch_one = AsyncMock(return_value={
        "risk_score": 0.65,
        "risk_state": "medium",
        "anomalies": ["unusual_login_time"],
    })
    pg.fetch_many = AsyncMock(return_value=[])
    return pg


def _make_mock_qdrant():
    qdrant = MagicMock()
    qdrant.search = MagicMock(return_value=[])
    return qdrant


def _build_graph(
    classification: dict,
    fp_patterns: list | None = None,
    escalation_manager=None,
):
    gateway = _make_mock_gateway(classification)
    redis = _make_mock_redis()
    postgres = _make_mock_postgres()
    qdrant = _make_mock_qdrant()

    if fp_patterns:
        redis.list_fp_patterns.return_value = [f"fp:{p['pattern_id']}" for p in fp_patterns]
        redis.get_fp_pattern.side_effect = lambda pid: next(
            (p for p in fp_patterns if p["pattern_id"] == pid), None
        )

    repo = InvestigationRepository(postgres)
    ioc = IOCExtractorAgent(gateway=gateway, redis_client=redis)
    enricher = ContextEnricherAgent(
        redis_client=redis, postgres_client=postgres, qdrant_client=qdrant,
    )
    ctem = CTEMCorrelatorAgent(postgres_client=postgres)
    atlas = ATLASMapperAgent(postgres_client=postgres, qdrant_client=qdrant)
    reasoning = ReasoningAgent(
        gateway=gateway, escalation_manager=escalation_manager,
    )
    response = ResponseAgent(postgres_client=postgres)
    fp = FPShortCircuit(redis_client=redis)

    return InvestigationGraph(
        repository=repo,
        ioc_extractor=ioc,
        context_enricher=enricher,
        ctem_correlator=ctem,
        atlas_mapper=atlas,
        reasoning_agent=reasoning,
        response_agent=response,
        fp_shortcircuit=fp,
    )


ENTITIES = {
    "accounts": [{"primary_value": "jsmith@example.com"}],
    "hosts": [{"primary_value": "web-01"}],
    "ips": [{"primary_value": "10.0.0.1"}],
}


class TestHappyPathIntegration:
    @pytest.mark.asyncio
    async def test_full_pipeline_auto_close(self):
        """RECEIVED → PARSING → ENRICHING → REASONING → RESPONDING → CLOSED."""
        graph = _build_graph({
            "classification": "true_positive",
            "confidence": 0.85,
            "severity": "high",
            "attack_techniques": ["T1566"],
            "atlas_techniques": [],
            "recommended_actions": [
                {"action": "monitor", "target": "web-01", "tier": 0},
            ],
            "reasoning": "Phishing detected.",
        })

        result = await graph.run(
            alert_id="ALERT-001",
            tenant_id="tenant-A",
            entities=ENTITIES,
            alert_title="Suspicious Email Activity",
            severity="high",
        )

        assert result.state == InvestigationState.CLOSED
        assert result.classification == "true_positive"
        assert result.confidence == 0.85
        assert result.llm_calls >= 1
        assert result.total_cost_usd > 0
        assert len(result.decision_chain) >= 3


class TestEscalationIntegration:
    @pytest.mark.asyncio
    async def test_escalation_flow(self):
        """Low confidence triggers Opus escalation."""
        escalation = MagicMock()
        escalation.should_escalate = MagicMock(return_value=True)
        escalation.record_escalation = MagicMock()

        gateway = _make_mock_gateway({})
        # First call: low confidence; second call: high confidence
        gateway.complete = AsyncMock(side_effect=[
            # IOC extraction
            MagicMock(
                content=json.dumps({"iocs": [{"type": "ip", "value": "10.0.0.1"}]}),
                metrics=MagicMock(cost_usd=0.005),
            ),
            # Reasoning (low confidence)
            MagicMock(
                content=json.dumps({
                    "classification": "suspicious",
                    "confidence": 0.4,
                    "severity": "critical",
                    "recommended_actions": [],
                }),
                metrics=MagicMock(cost_usd=0.05),
            ),
            # Escalation (high confidence)
            MagicMock(
                content=json.dumps({
                    "classification": "true_positive",
                    "confidence": 0.9,
                    "severity": "critical",
                    "recommended_actions": [],
                }),
                metrics=MagicMock(cost_usd=0.15),
            ),
        ])

        redis = _make_mock_redis()
        postgres = _make_mock_postgres()
        qdrant = _make_mock_qdrant()

        repo = InvestigationRepository(postgres)
        graph = InvestigationGraph(
            repository=repo,
            ioc_extractor=IOCExtractorAgent(gateway=gateway, redis_client=redis),
            context_enricher=ContextEnricherAgent(
                redis_client=redis, postgres_client=postgres, qdrant_client=qdrant,
            ),
            ctem_correlator=CTEMCorrelatorAgent(postgres_client=postgres),
            atlas_mapper=ATLASMapperAgent(postgres_client=postgres, qdrant_client=qdrant),
            reasoning_agent=ReasoningAgent(
                gateway=gateway, escalation_manager=escalation,
            ),
            response_agent=ResponseAgent(postgres_client=postgres),
            fp_shortcircuit=FPShortCircuit(redis_client=redis),
        )

        result = await graph.run(
            alert_id="ALERT-002",
            tenant_id="tenant-A",
            entities=ENTITIES,
            severity="critical",
        )

        assert result.confidence == 0.9
        assert result.llm_calls >= 2
        escalation.record_escalation.assert_called_once()


class TestDestructiveActionIntegration:
    @pytest.mark.asyncio
    async def test_destructive_action_pauses(self):
        """Tier 2 action triggers AWAITING_HUMAN."""
        graph = _build_graph({
            "classification": "true_positive",
            "confidence": 0.9,
            "severity": "critical",
            "recommended_actions": [
                {"action": "isolate_endpoint", "target": "web-01", "tier": 2},
            ],
        })

        result = await graph.run(
            alert_id="ALERT-003",
            tenant_id="tenant-A",
            entities=ENTITIES,
            severity="critical",
        )

        assert result.state == InvestigationState.AWAITING_HUMAN
        assert result.requires_human_approval is True


class TestFPShortCircuitIntegration:
    @pytest.mark.asyncio
    async def test_fp_skips_enrichment(self):
        """Known FP pattern closes before any LLM calls."""
        fp_patterns = [{
            "pattern_id": "FP-001",
            "alert_name_regex": ".*Exchange.*Unusual.*",
            "entity_patterns": [
                {"type": "account", "value_regex": ".*service.*"},
            ],
            "status": "approved",
        }]

        graph = _build_graph(
            classification={},  # should never be called
            fp_patterns=fp_patterns,
        )

        result = await graph.run(
            alert_id="ALERT-FP",
            tenant_id="tenant-A",
            entities={
                "accounts": [{"primary_value": "service-account-01"}],
            },
            alert_title="Exchange Unusual Activity Alert",
        )

        assert result.state == InvestigationState.CLOSED
        assert result.classification == "false_positive"
        # IOC extractor LLM call happens before FP check
        assert result.llm_calls <= 1


class TestErrorResilienceIntegration:
    @pytest.mark.asyncio
    async def test_failure_transitions_to_failed(self):
        """Unrecoverable error produces FAILED state."""
        graph = _build_graph({})
        # Break the IOC extractor
        graph._ioc = AsyncMock()
        graph._ioc.execute = AsyncMock(side_effect=RuntimeError("Boom"))

        result = await graph.run(
            alert_id="ALERT-FAIL",
            tenant_id="tenant-A",
            entities={},
        )

        assert result.state == InvestigationState.FAILED
        assert any("error" in str(d) for d in result.decision_chain)


class TestAuditTrailIntegration:
    @pytest.mark.asyncio
    async def test_decision_chain_complete(self):
        """Every state transition recorded in decision_chain."""
        graph = _build_graph({
            "classification": "false_positive",
            "confidence": 0.95,
            "severity": "low",
            "recommended_actions": [],
        })

        result = await graph.run(
            alert_id="ALERT-AUDIT",
            tenant_id="tenant-A",
            entities=ENTITIES,
            severity="low",
        )

        agents_in_chain = [d.get("agent", "") for d in result.decision_chain]
        assert "ioc_extractor" in agents_in_chain
        assert "graph" in agents_in_chain  # enrichment transition
